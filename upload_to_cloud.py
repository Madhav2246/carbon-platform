from google.cloud import storage
import os
from datetime import datetime

print("=" * 70)
print("‚òÅÔ∏è  UPLOADING MODEL TO GOOGLE CLOUD STORAGE")
print("=" * 70)

# ============================================================================
# CONFIGURATION - UPDATE THESE VALUES
# ============================================================================
PROJECT_ID = "carbonsense-project"  # üî¥ CHANGE THIS TO YOUR PROJECT ID
BUCKET_NAME = f"carbonsense-data-hruthik123"  # üî¥ CHANGE THIS TO YOUR BUCKET NAME
MODEL_VERSION = "v1"

print(f"\nüîß Configuration:")
print(f"   Project ID:    {PROJECT_ID}")
print(f"   Bucket Name:    {BUCKET_NAME}")
print(f"   Model Version:  {MODEL_VERSION}")

# ============================================================================
# INITIALIZE STORAGE CLIENT
# ============================================================================
print(f"\nüîê Connecting to Google Cloud Storage...")
try:
    storage_client = storage.Client(project=PROJECT_ID)
    bucket = storage_client.bucket(BUCKET_NAME)
    print(f"‚úÖ Connected successfully!")
except Exception as e:
    print(f"‚ùå Error connecting to Cloud Storage: {e}")
    print(f"   Make sure:")
    print(f"   1. GOOGLE_APPLICATION_CREDENTIALS is set")
    print(f"   2. Project ID is correct")
    exit(1)

# ============================================================================
# FILES TO UPLOAD
# ============================================================================
files_to_upload = [
    ('model_artifacts/carbon_model.pkl', 'model'),
    ('model_artifacts/metrics.json', 'metadata'),
    ('label_encoder.pkl', 'preprocessor'),
    ('scaler.pkl', 'preprocessor')
]

print(f"\nüìã Files to upload:")
for local_file, file_type in files_to_upload:
    if os.path.exists(local_file):
        file_size_kb = os.path.getsize(local_file) / 1024
        print(f"   ‚úÖ {local_file:40s} ({file_size_kb:6.1f} KB)")
    else:
        print(f"   ‚ùå {local_file:40s} (NOT FOUND!)")

# ============================================================================
# UPLOAD EACH FILE
# ============================================================================
print(f"\nüì§ Uploading files...")

for local_file, file_type in files_to_upload:
    if not os.path.exists(local_file):
        print(f"‚ö†Ô∏è  Skipping {local_file} (not found)")
        continue
    
    try:
        # Create cloud path: models/v1/filename
        cloud_path = f"models/{MODEL_VERSION}/{os.path.basename(local_file)}"
        
        print(f"\n   Uploading: {local_file}")
        blob = bucket.blob(cloud_path)
        blob.upload_from_filename(local_file)
        
        # Get file size
        file_size_mb = blob.size / (1024 * 1024)
        print(f"   ‚úÖ Success! ({file_size_mb:.2f} MB)")
        print(f"   üìç Location: gs://{BUCKET_NAME}/{cloud_path}")
        
    except Exception as e:
        print(f"   ‚ùå Error uploading {local_file}: {e}")

# ============================================================================
# SUMMARY
# ============================================================================
print("\n" + "=" * 70)
print("‚úÖ UPLOAD COMPLETE!")
print("=" * 70)

print(f"\nüîó Your model files are now in Cloud Storage at:")
print(f"   gs://{BUCKET_NAME}/models/{MODEL_VERSION}/")

print(f"\nüìã Files uploaded:")
print(f"   ‚úÖ carbon_model.pkl")
print(f"   ‚úÖ metrics.json")
print(f"   ‚úÖ label_encoder.pkl")
print(f"   ‚úÖ scaler.pkl")

print(f"\nüöÄ NEXT STEP:")
print(f"   1. Run: python package_for_deployment.py")
print(f"   2. Then deploy to Vertex AI")

print("\n" + "=" * 70)